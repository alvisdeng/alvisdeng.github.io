<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>优化绝技-梯度下降(Gradient Descent) | 阿平的自我修养</title><meta name="keywords" content="Optimization"><meta name="author" content="阿平"><meta name="copyright" content="阿平"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="在线性模型中, 我们除了使用最小二乘法 (或者称为正规方程法), 我们还可以使用一种常用的凸优化技术: 梯度下降!  它的主要目的是通过迭代找到目标函数的最小值,     梯度下降法的基本思想可以类比为一个下山的过程.   假设这样一个场景: 一个人被困在山上, 需要从山上下来(找到山的最低点, 也就是山谷). 但此时山上的浓雾很大, 导致可视度很低; 因此, 下山的路径就无法确定, 必须利用自己">
<meta property="og:type" content="article">
<meta property="og:title" content="优化绝技-梯度下降(Gradient Descent)">
<meta property="og:url" content="https://www.facequant.com/2020/11/12/%E4%BC%98%E5%8C%96%E7%BB%9D%E6%8A%80-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-Gradient-Descent/index.html">
<meta property="og:site_name" content="阿平的自我修养">
<meta property="og:description" content="在线性模型中, 我们除了使用最小二乘法 (或者称为正规方程法), 我们还可以使用一种常用的凸优化技术: 梯度下降!  它的主要目的是通过迭代找到目标函数的最小值,     梯度下降法的基本思想可以类比为一个下山的过程.   假设这样一个场景: 一个人被困在山上, 需要从山上下来(找到山的最低点, 也就是山谷). 但此时山上的浓雾很大, 导致可视度很低; 因此, 下山的路径就无法确定, 必须利用自己">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/alvisdeng/ImgHouse@main/gradient-descent-local-minima.png">
<meta property="article:published_time" content="2020-11-12T12:21:02.000Z">
<meta property="article:modified_time" content="2020-12-25T18:32:30.895Z">
<meta property="article:author" content="阿平">
<meta property="article:tag" content="Optimization">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/alvisdeng/ImgHouse@main/gradient-descent-local-minima.png"><link rel="shortcut icon" href="/images/panda.png"><link rel="canonical" href="https://www.facequant.com/2020/11/12/%E4%BC%98%E5%8C%96%E7%BB%9D%E6%8A%80-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-Gradient-Descent/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="_MQwHkUtYfuk8J0qAPSV-zpAugCAnNbea8RvdD-C5DA"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script async="async" src="https://www.googletagmanager.com/gtag/js?id=UA-153134572-1"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-153134572-1');
</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'mediumZoom',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}

// https://stackoverflow.com/questions/16839698/jquery-getscript-alternative-in-native-javascript
const getScript = url => new Promise((resolve, reject) => {
  const script = document.createElement('script')
  script.src = url
  script.async = true
  script.onerror = reject
  script.onload = script.onreadystatechange = function() {
    const loadState = this.readyState
    if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
    script.onload = script.onreadystatechange = null
    resolve()
  }
  document.head.appendChild(script)
})</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2020-12-26 02:32:30'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 5.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/images/human.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div id="body-wrap"><header class="no-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">阿平的自我修养</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">优化绝技-梯度下降(Gradient Descent)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-11-12T12:21:02.000Z" title="发表于 2020-11-12 20:21:02">2020-11-12</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-12-25T18:32:30.895Z" title="更新于 2020-12-26 02:32:30">2020-12-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Machine-Learning/">Machine Learning</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">4.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>14分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div><article class="post-content" id="article-container"><p>在线性模型中, 我们除了使用最小二乘法 (或者称为正规方程法), 我们还可以使用一种常用的凸优化技术: <strong>梯度下降!</strong>  它的主要目的是通过迭代找到目标函数的最小值, </p>
<blockquote>
<p>  梯度下降法的基本思想可以类比为一个下山的过程.</p>
<p>  假设这样一个场景: 一个人被困在山上, 需要从山上下来(找到山的最低点, 也就是山谷). 但此时山上的浓雾很大, 导致可视度很低; 因此, 下山的路径就无法确定, 必须利用自己周围的信息一步一步地找到下山的路. 这个时候, 便可利用梯度下降算法来帮助自己下山. <strong>怎么做呢? 首先以他当前的所处的位置为基准, 寻找这个位置最陡峭的地方, 然后朝着下降方向走一步, 然后又继续以当前位置为基准, 再找最陡峭的地方, 再走直到最后到达最低处; 同理上山也是如此, 只是这时候就变成梯度上升算法了.</strong></p>
<p>  从上面的解释可以看出, 梯度下降不一定能够找到全局的最优解, 有可能是一个局部最优解. 当然, 如果损失函数是严格凸函数, 梯度下降法得到的解就一定是全局最优解.</p>
<p>  <img src="https://i.loli.net/2020/10/04/KAjc83rfMSbHlwu.png" alt="img"></p>
</blockquote>
<p>梯度下降的基本过程就和下山的场景很类似. 根据之前的场景假设, 最快的下山的方式就是找到当前位置最陡峭的方向, 然后沿着此方向向下走, <strong>对应到函数中, 就是找到给定点的梯度</strong>, 然后朝着梯度相反的方向, 就能让函数值下降的最快! <strong>因为梯度的方向就是函数之变化最快的方向.</strong></p>
<h3 id="1-Why-Gradient"><a href="#1-Why-Gradient" class="headerlink" title="1. Why Gradient?"></a>1. Why Gradient?</h3><p>所以, 我们重复利用这个方法, 反复求取梯度, 最后就能到达局部的最小值, 这就类似于我们下山的过程. 而求取梯度就确定了最陡峭的方向, 也就是场景中测量方向的手段. 那么为什么梯度的方向就是最陡峭的方向呢? 接下来, 我们从微分开始讲起.</p>
<p>看待微分的意义, 可以有不同的角度, 最常用的两种是:</p>
<ul>
<li><em>函数图像中, 某点的切线的斜率</em></li>
<li><em>函数的变化率</em></li>
</ul>
<p>单变量微分我们这里就不介绍了, 主要看一下多变量微分. 当函数有多个变量的时候, 即分别对每个变量进行求微分. 梯度实际上就是多变量微分的一般化. 这里以二元函数 $z=f(x,y)$ 为例讲解偏导数, 其余情况以此类推.</p>
<p>由于二元函数具有两个自变量 $(x,y)$, 因此函数图像为一个曲面. 与一元函数类似, <strong>如何计算二元函数对曲面上一点</strong> $(x_0,y_0)$ <strong>的变化率呢?</strong> 此处需要注意的是, <strong>因为过曲面上一点可以作出无数条切线, 因此函数在该点也具有无数个变化率.</strong> 为了简单起见, 可以<strong>先考虑函数沿着两个坐标轴 $x$ 轴和 $y$ 轴方向的变化率.</strong></p>
<ul>
<li>当自变量 $y$ 固定在 $y_0$, 函数在点 $x_0$ 处的变化率称为函数在点 $(x_0,y_0)$ 处对 $x$ 的偏导数, 记作 $f_x(x_0,y_0)$;</li>
<li>当自变量 $x$ 固定在 $x_0$, 函数在点 $y_0$ 处的变化率称为函数在点 $(x_0,y_0)$ 处对 $y$ 的偏导数, 记作 $f_y(x_0,y_0)$;</li>
</ul>
<p><img src="https://i.loli.net/2020/10/05/B4RAzTwtPxiUQIq.png" alt="image-20201005113705980" style="zoom: 50%;" /></p>
<p><strong>可能到这里, 读者就已经发现偏导数的局限性了, 原来我们学到的偏导数指的是多元函数沿坐标轴的变化率, 但是我们往往很多时候要考虑多元函数沿任意方向的变化率, 那么就引出了方向导数.</strong></p>
<p>因此, 如何求出函数在点 $(x_0,y_0)$ 处沿某一方向的变化率呢? 万变不离其宗, 此时仍然按照变化率的定义去求解, 即只需求出函数的增量与自变量沿着某一方向增量比值的极限即可. </p>
<p>假设某一方向的单位向量为 $e_l=(\cos\alpha,\sin\alpha)$, $\alpha$ 为此向量与 $x$ 轴正向夹角. 显然, $\alpha$ 不同, 此向量能够表示任意方向的单位向量. 当点 $(x_0,y_0)$ 沿着该方向产生一个增量 $t$ 到达点 $(x_0+t\cos\alpha,y_0+t\sin\alpha)$ 时, 函数 $z$ 也会产生一个增量 $\triangle z=f(x_0+t\cos\alpha,y_0+t\sin\alpha)-f(x_0,y_0)$, 此时函数沿此方向的变化率为</p>
<script type="math/tex; mode=display">
\lim\limits_{t\rightarrow0^+}\frac{f(x_0+t\cos\alpha,y_0+t\sin\alpha)-f(x_0,y_0)}{t}=f_x(x_0,y_0)\cos\alpha+f_y(x_0,y_0)\sin\alpha</script><p>在了解了多元函数的方向导数之后, 一个很自然的问题是: 既然函数在点 $(x_0,y_0)$ 处沿着任意的方向都有一个变化率, <strong>那么沿着哪个方向 ($\alpha=?$) 函数的变化率最大呢?</strong></p>
<p>根据上面的推导, 我们知道函数 $z=f(x,y)$ 沿着任意方向 ($\alpha$ 取任意值) 的变化率为</p>
<script type="math/tex; mode=display">
f_x(x_0,y_0)\cos\alpha+f_y(x_0,y_0)\sin\alpha</script><p>因此接下来只需求得使其达到最大值时的 $\alpha$ 便可以解决上诉问题. 由于上式可以看成两个向量的内积, 令</p>
<script type="math/tex; mode=display">
\mathbf{g}=(f_x(x_0,y_0),f_y(x_0,y_0)) \\
\mathbf{e}_l=(\cos\alpha,\sin\alpha)</script><p>则</p>
<script type="math/tex; mode=display">
f_x(x_0,y_0)\cos\alpha+f_y(x_0,y_0)\sin\alpha=\mathbf{g}\cdot\mathbf{e}_l=|\mathbf{g}||\mathbf{e}_l|\cos\theta=|\mathbf{g}|\cos\theta</script><p>其中, $\theta$ 为 $\mathbf{g}$ 和 $\mathbf{e}_l$ 的夹角, 根据上式, 我们可以得出结论:</p>
<ul>
<li>当 $\theta=0$, 即 $\mathbf{g}$ 和 $\mathbf{e}_l$ 方向相同时, 函数的变化率最大, 且在点 $(x_0,y_0)$ 呈上升趋势;</li>
<li>当 $\theta=\pi$, 即 $\mathbf{g}$ 和 $\mathbf{e}_l$ 方向相反时, 函数的变化率最大, 且在点 $(x_0,y_0)$ 呈下降趋势;</li>
</ul>
<p>最后, 当点 $(x_0,y_0)$ 确定后, 向量 $\mathbf{g}$ 也随之确定. 由于向量 $\mathbf{g}$ 的方向为函数值增加最快的方向, 而此方向经常被用于实际生活中, 因此为便于表述, 人们为其取了一个名字—梯度. 换而言之, <strong>多元函数在某一点的梯度是一个非常特殊的向量, 其由多元函数对每个变量的偏导数组成 (这即是为什么求梯度的时候需要对各个变量求偏导的原因), 其方向为函数在该点增加最快的方向, 大小为函数在该点的最大变化率.</strong></p>
<h3 id="2-Example"><a href="#2-Example" class="headerlink" title="2. Example"></a>2. Example</h3><h4 id="2-1-Single-Variable"><a href="#2-1-Single-Variable" class="headerlink" title="2.1 Single Variable"></a>2.1 Single Variable</h4><p>我们首先给出数学公式: $\theta_1=\theta_0-\alpha\triangledown\mathbf{J}(\theta)$</p>
<p>此公式的意义是: $\mathbf{J}$ 是关于 $\theta$ 的一个函数, 我们当前所处的位置为 $\theta_0$ 点, 要从这个点走到 $\mathbf{J}$ 的最小值点, 也就是山底. 首先我们先确定前进的方向, 也就是梯度的反向, 然后走一段距离的步长, 也就是 $\alpha$, 走完这个段步长, 就到达了 $\theta_1$ 这个点!</p>
<p>$\alpha$ 在梯度下降算法中被称作为学习率或者步长, 意味着我们可以通过 $\alpha$ 来控制每一步走的距离, 以保证不要步子跨的太大扯着蛋, 哈哈, 其实就是不要走太快, 错过了最低点. 同时也要保证不要走的太慢, 导致太阳下山了, 还没有走到山下. 所以 $\alpha$ 的选择在梯度下降法中往往是很重要的!</p>
<blockquote>
<p>  注:</p>
<p>  梯度前加一个负号, 就意味着朝着梯度相反的方向前进! 我们在前文提到, 梯度的方向实际就是函数在此点上升最快的方向! 而我们需要朝着下降最快的方向走, 自然就是负的梯度的方向, 所以此处需要加上负号; <strong>那么如果时上坡, 也就是梯度上升算法, 当然就不需要添加负号了.</strong></p>
</blockquote>
<p>我们利用上述的数学公式来看一个个简单的梯度下降的例子. 我们假设有一个单变量的函数</p>
<p>$\mathbf{J}(\theta)=\theta^2$</p>
<p>函数的微分, 直接求导就可以得到</p>
<p>$\mathbf{J}’(\theta)=2\theta$</p>
<p>初始化, 也就是起点, 起点可以随意的设置, 这里设置为1</p>
<p>$\theta_0=1$</p>
<p>学习率也可以随意的设置, 这里设置为0.4</p>
<p>$\alpha=0.4$</p>
<p>根据梯度下降的计算公式</p>
<p> $\theta_1=\theta_0-\alpha\triangledown\mathbf{J}(\theta)$</p>
<p>我们开始进行梯度下降的迭代计算过程</p>
<p><img src="https://cdn.jsdelivr.net/gh/alvisdeng/ImgHouse@main/image-20201220010006930.png" alt="image-20201220010006930" style="zoom:50%;" /></p>
<p>如图, 经过四次的运算, 也就是走了四步, 基本就抵达了函数的最低点, 也就是山底</p>
<p><img src="https://i.loli.net/2020/10/05/DFHAwxhE3etCyOc.png" alt="image-20201005124317847" style="zoom: 50%;" /></p>
<h4 id="2-2-Multi-Varibles"><a href="#2-2-Multi-Varibles" class="headerlink" title="2.2 Multi Varibles"></a>2.2 Multi Varibles</h4><p>我们假设有一个目标函数</p>
<p>$\mathbf{J}(\theta)=\theta_1^2+\theta_2^2$</p>
<p>现在要通过梯度下降法计算这个函数的最小值. 我们通过观察就能发现最小值其实就是 (0, 0)点. 但是接下来, 我们会从梯度下降算法开始一步步计算到这个最小值!</p>
<p>我们假设初始的起点为</p>
<p>$\theta_0=(1,3)$</p>
<p>初始的学习率为</p>
<p>$\alpha=0.1$</p>
<p>函数的梯度为</p>
<p>$\triangledown\mathbf{J}(\theta)=<2\theta_1,2\theta_2>$</p>
<p>进行多次迭代</p>
<p><img src="https://cdn.jsdelivr.net/gh/alvisdeng/ImgHouse@main/image-20201220010136155.png" alt="image-20201220010136155" style="zoom:50%;" /></p>
<blockquote>
<p>  我们此时注意到, 在更新 $\theta$ 的时候, 我们是同步更新. 具体来说, 我们在这里有两个参数, 我们是同步更新的, 而不是先计算其中一个参数然后用这个新的值去计算另外一个参数.</p>
</blockquote>
<p>我们发现，已经基本靠近函数的最小值点</p>
<p><img src="https://i.loli.net/2020/10/05/jr1hW2ubmY4NcBp.png" alt="image-20201005125448139" style="zoom: 50%;" /></p>
<h4 id="2-3-Linear-Regression"><a href="#2-3-Linear-Regression" class="headerlink" title="2.3 Linear Regression"></a>2.3 Linear Regression</h4><p>我们用 Python 来实现一个简单的梯度下降算法. 场景是一个简单的线性回归的例子: 假设现在我们有一系列的点, 如下图所示</p>
<p><img src="https://i.loli.net/2020/10/05/VTGt4zFDsnLl9Jr.png" alt="image-20201005130025746" style="zoom:50%;" /></p>
<p>首先, 我们需要定义一个代价函数, 在此我们选择均方误差代价函数</p>
<p>$\mathbf{J}(\theta)=\frac{1}{2m}\sum_{i=1}^m(h_{\theta}(x^{(i)}-y^{(i)})^2$</p>
<p>此公式中:</p>
<ul>
<li><p>m是数据集中数据点的个数, 也就是样本数;</p>
</li>
<li><p>$\frac{1}{2}$ 是一个常量, 这样是为了在求梯度的时候, 二次方乘下来的 2 就和这里的 $\frac{1}{2}$ 抵消了, 自然就没有多余的常数系数, 方便后续的计算, 同时对结果不会有影响;</p>
</li>
<li><p>$y$ 是数据集中每个点的真实 $y$ 坐标的值, 也就是类标签;</p>
</li>
<li><p>$h$ 是我们的预测函数 (假设函数), 根据每一个输入$x$, 根据 $\theta$ 计算得到预测的 $y$ 值, 即</p>
<p>$h_{\theta}(x^{(i)})=\theta_0+\theta_1x^{(i)}$</p>
</li>
</ul>
<p>我们可以根据代价函数看到, 代价函数中的变量有两个, 所以是一个多变量的梯度下降问题, 求解出代价函数的梯度, 也就是分别对两个变量进行微分</p>
<script type="math/tex; mode=display">
\triangledown\mathbf{J}(\theta)=<\frac{\delta\mathbf{J}}{\delta\theta_0},\frac{\delta\mathbf{J}}{\delta\theta_1}> \\
\frac{\delta\mathbf{J}}{\delta\theta_0}=\frac{1}{m}\sum_{i=1}^m(h_{\theta}(x^{(i)}-y^{(i)}) \\
\frac{\delta\mathbf{J}}{\delta\theta_1}=\frac{1}{m}\sum_{i=1}^m(h_{\theta}(x^{(i)}-y^{(i)})x^{(i)}</script><p>根据, 我们之前在线性回归 <code>Normal Equation Method</code> 那里所提到的, 我们可以将目标函数和以及其梯度给转换成矩阵形式</p>
<script type="math/tex; mode=display">
\mathbf{J}(\theta)=\frac{1}{2m}(X\Theta-\overrightarrow{y})^T(X\Theta-\overrightarrow{y}) \\
\triangledown\mathbf{J}(\theta)=\frac{1}{m}X^T(X\Theta-\overrightarrow{y})</script><p>代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这其实是一个 batch gradient descent</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集大小, 即 20 个数据点</span></span><br><span class="line">m = <span class="number">20</span></span><br><span class="line"><span class="comment"># Design Matrix</span></span><br><span class="line">x0 = np.ones((m,<span class="number">1</span>))</span><br><span class="line">x1 = np.arange(<span class="number">1</span>,m+<span class="number">1</span>).reshape(m,<span class="number">1</span>)</span><br><span class="line">X = np.hstack((x0,x1))</span><br><span class="line"><span class="comment"># 对应的 y </span></span><br><span class="line">y = np.array([</span><br><span class="line">    <span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">11</span>,<span class="number">8</span>,<span class="number">12</span>,</span><br><span class="line">    <span class="number">11</span>,<span class="number">13</span>,<span class="number">13</span>,<span class="number">16</span>,<span class="number">17</span>,<span class="number">18</span>,<span class="number">17</span>,<span class="number">19</span>,<span class="number">21</span></span><br><span class="line">]).reshape(m,<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 学习率</span></span><br><span class="line">alpha = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义代价函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost_function</span>(<span class="params">theta,X,y</span>):</span></span><br><span class="line">    diff = np.dot(X,theta) - y</span><br><span class="line">    <span class="keyword">return</span> (<span class="number">1</span>/<span class="number">2</span>*m) * np.dot(diff.T,diff)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义代价函数对应的梯度函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_function</span>(<span class="params">theta,X,y</span>):</span></span><br><span class="line">     diff = np.dot(X,theta) - y</span><br><span class="line">     <span class="keyword">return</span> <span class="number">1</span>/m * np.dot(X.T,diff)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度下降迭代</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_descent</span>(<span class="params">X,y,alpha</span>):</span></span><br><span class="line">    theta = np.array([<span class="number">1</span>,<span class="number">1</span>]).reshape(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">    gradient = gradient_function(theta,X,y)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> <span class="built_in">all</span>(<span class="built_in">abs</span>(gradient) &lt;= <span class="number">1e-5</span>):</span><br><span class="line">        theta = theta - alpha*gradient</span><br><span class="line">        gradient = gradient_function(theta,X,y)</span><br><span class="line">    <span class="keyword">return</span> theta</span><br></pre></td></tr></table></figure>
<h3 id="3-Algorithm"><a href="#3-Algorithm" class="headerlink" title="3. Algorithm"></a>3. Algorithm</h3><p>一般线性回归函数的假设函数为</p>
<script type="math/tex; mode=display">
h_{\theta}=\sum_{j=0}^n\theta_jx_j</script><p>对应的损失函数形式为</p>
<script type="math/tex; mode=display">
J(\theta)=\frac{1}{2m}\sum_{i=1}^m(h_\theta(x_i)-y_i)^2</script><p>下图为一个二维参数 $(\theta_0,\theta_1)$ 组对应损失函数的可视化图</p>
<p><img src="https://i.loli.net/2020/10/05/MS2PxbVNDIzeYyT.png" alt="image-20201005145948910" style="zoom:50%;" /></p>
<p>接下来, 我们介绍三种不同的梯度下降算法:</p>
<ul>
<li><strong>批量梯度下降法 (Batch Gradient Descent)</strong></li>
<li><strong>随机梯度下降法 (Stochastic Gradient Descent)</strong></li>
<li><strong>小批量梯度下降法 (Mini-batch Gradient Descent)</strong></li>
</ul>
<h4 id="3-1-Batch-Gradient-Descent"><a href="#3-1-Batch-Gradient-Descent" class="headerlink" title="3.1 Batch Gradient Descent"></a>3.1 Batch Gradient Descent</h4><p>批量梯度下降法 (Batch Gradient Descent, 简称BGD) 是梯度下降法最原始的形式, 它的具体思路是在更新每一参数时都使用所有的样本来进行更新, 其数学形式如下:</p>
<p><strong>Step 1: 对上述的损失函数求偏导</strong></p>
<script type="math/tex; mode=display">
\frac{\delta J(\theta)}{\delta\theta_j}=\frac{1}{m}\sum_{i=1}^m(h_{\theta}(x_i)-y_i)x_j</script><p><strong>Step 2: 由于是最小化风险函数，所以按照每个参数 $\theta$ 的梯度负方向来更新每个 $\theta$</strong></p>
<script type="math/tex; mode=display">
\theta_{j_{new}}=\theta_{j_{old}}-\frac{1}{m}\sum_{i=1}^m(h_{\theta}(x_i)-y_i)x_j</script><p><strong>具体的伪代码形式为</strong></p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{repeat}&\{ \\
&\theta_{j_{new}}=\theta_{j_{old}}-\frac{1}{m}\sum_{i=1}^m(h_{\theta}(x_i)-y_i)x_j\\
&(for\ every\ j=0,...,n)\\
\}
\end{aligned}</script><p>从上面公式可以注意到, 它得到的是一个全局最优解, 但是每迭代一步, 都要用到训练集所有的数据, 如果样本数目 $m$ 很大, 那么可想而知这种方法的迭代速度! 所以, 这就引入了另外一种方法, 随机梯度下降.</p>
<ul>
<li><strong>优点:</strong> 对于严格凸函数而言, 它得到的是一个<strong>全局最优解</strong>, 且易于理解和<strong>并行实现</strong>;</li>
<li><strong>缺点:</strong> 当样本数目很多时, 训练过程会很慢, 因为每一次计算梯度 (也就是更新参数) 的时候都需要所有的样本;</li>
</ul>
<p>从迭代的次数上来看, <strong>BGD迭代的次数相对较少.</strong> 其迭代的收敛曲线示意图可以表示如下:</p>
<p><img src="https://i.loli.net/2020/10/05/APwDbIqN3Gz6M7Q.png" alt="image-20201005152031253" style="zoom:50%;" /></p>
<h4 id="3-2-Stochastic-Gradient-Descent"><a href="#3-2-Stochastic-Gradient-Descent" class="headerlink" title="3.2 Stochastic Gradient Descent"></a>3.2 Stochastic Gradient Descent</h4><p>由于批量梯度下降法在更新每一个参数时, 都需要所有的训练样本, 所以训练过程会随着样本数量的加大而变得异常的缓慢. 随机梯度下降法 (Stochastic Gradient Descent, 简称SGD) 正是为了解决批量梯度下降法这一弊端而提出的.</p>
<p>它是利用<strong>每个样本</strong>的<strong>损失函数</strong>对 $\theta$ 求偏导得到对应的梯度, 来更新 $\theta$:</p>
<script type="math/tex; mode=display">
\theta_{j_{new}}=\theta_{j_{old}}-\alpha(h_{\theta}(x_i)-y_i)x_j</script><p><strong>具体的伪代码形式为</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/alvisdeng/ImgHouse@main/image-20201220015307108.png" alt="image-20201220015307108" style="zoom:50%;" /></p>
<p>随机梯度下降是通过每个样本来迭代更新一次, 如果样本量很大的情况 (例如几十万), 那么可能只用其中几万条或者几千条的样本, 就已经将theta迭代到最优解了, 对比上面的批量梯度下降, 迭代一次需要用到十几万训练样本, 一次迭代不可能最优, 如果迭代10次的话就需要遍历训练样本10次. 但是, SGD伴随的一个问题是噪音较BGD要多, 使得SGD并不是每次迭代都向着整体最优化方向.</p>
<ul>
<li><strong>优点:</strong> 训练速度快;</li>
<li><strong>缺点:</strong> 准确度下降, 不易于并行实现;</li>
</ul>
<blockquote>
<p>  注:</p>
<p>  一般在生产中的场景 objective function 都不是单峰的, 自然, BGD 就不一定做到全局最优, 反而是sgd更可能跳出局部最优.</p>
</blockquote>
<p>从迭代的次数上来看, SGD迭代的次数较多, 在解空间的搜索过程看起来很盲目. 其迭代的收敛曲线示意图可以表示如下:</p>
<p><img src="https://i.loli.net/2020/10/05/NGiwXMVInc16aq3.png" alt="image-20201005160111136" style="zoom:50%;" /></p>
<h4 id="3-3-Mini-batch-Gradient-Descent"><a href="#3-3-Mini-batch-Gradient-Descent" class="headerlink" title="3.3 Mini-batch Gradient Descent"></a>3.3 Mini-batch Gradient Descent</h4><p>有上述的两种梯度下降法可以看出, 其各自均有优缺点, 那么能不能在两种方法的性能之间取得一个折衷呢? 即, 算法的训练过程比较快, 而且也要保证最终参数训练的准确率, 而这正是小批量梯度下降法 (Mini-batch Gradient Descent, 简称MBGD) 的初衷.</p>
<p>MBGD 在每次更新参数时使用 b 个样本 (b一般为10), 其具体的伪代码形式为:</p>
<p><img src="https://cdn.jsdelivr.net/gh/alvisdeng/ImgHouse@main/image-20201220015703862.png" alt="image-20201220015703862" style="zoom:50%;" /></p>
<h3 id="4-Conclusion"><a href="#4-Conclusion" class="headerlink" title="4. Conclusion"></a>4. Conclusion</h3><ol>
<li>批梯度下降每次更新使用了所有的训练数据, 最小化损失函数, <strong>如果只有一个极小值, 那么批梯度下降是考虑了训练集所有数据, 是朝着最小值迭代运动的, </strong>但是缺点是如果样本值很大的话, 更新速度会很慢.</li>
<li>随机梯度下降在每次更新的时候, 只考虑了一个样本点, 这样会大大加快训练数据, 也恰好是批梯度下降的缺点, 但是有可能由于训练数据的噪声点较多, <strong>那么每一次利用噪声点进行更新的过程中, 就不一定是朝着极小值方向更新, 但是由于更新多轮, 整体方向还是大致朝着极小值方向更新, 又提高了速度.</strong></li>
<li>小批量梯度下降法是<strong>为了解决批梯度下降法的训练速度慢, 以及随机梯度下降法的准确性综合而来, 但是这里注意, 不同问题的batch是不一样的.</strong></li>
</ol>
<p><img src="https://i.loli.net/2020/10/05/mSfG68M3LPUdnHq.png" alt="img"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">阿平</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://www.facequant.com/2020/11/12/%E4%BC%98%E5%8C%96%E7%BB%9D%E6%8A%80-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-Gradient-Descent/">https://www.facequant.com/2020/11/12/%E4%BC%98%E5%8C%96%E7%BB%9D%E6%8A%80-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-Gradient-Descent/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.facequant.com" target="_blank">阿平的自我修养</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Optimization/">Optimization</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/alvisdeng/ImgHouse@main/gradient-descent-local-minima.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/11/12/%E8%AF%A6%E8%A7%A3%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-Logistic-Regression/"><img class="prev-cover" src="https://cdn.jsdelivr.net/gh/alvisdeng/ImgHouse@main/sigmoid.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">详解逻辑回归(Logistic Regression)</div></div></a></div><div class="next-post pull-right"><a href="/2020/11/12/%E8%AF%A6%E8%A7%A3%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-Linear-Regression/"><img class="next-cover" src="https://cdn.jsdelivr.net/gh/alvisdeng/ImgHouse@main/1_QiU6DcP_r9qWLznMw0-M_Q.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">详解线性回归(Linear Regression)</div></div></a></div></nav></div><div class="aside_content" id="aside_content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="card-content"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Why-Gradient"><span class="toc-text">1. Why Gradient?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Example"><span class="toc-text">2. Example</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-Single-Variable"><span class="toc-text">2.1 Single Variable</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-Multi-Varibles"><span class="toc-text">2.2 Multi Varibles</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-Linear-Regression"><span class="toc-text">2.3 Linear Regression</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Algorithm"><span class="toc-text">3. Algorithm</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-Batch-Gradient-Descent"><span class="toc-text">3.1 Batch Gradient Descent</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-Stochastic-Gradient-Descent"><span class="toc-text">3.2 Stochastic Gradient Descent</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-Mini-batch-Gradient-Descent"><span class="toc-text">3.3 Mini-batch Gradient Descent</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-Conclusion"><span class="toc-text">4. Conclusion</span></a></li></ol></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 By 阿平</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.spacingElementById('content-inner')
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.spacingElementById('content-inner')
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div></body></html>